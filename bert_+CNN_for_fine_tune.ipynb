{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert +CNN for fine tune",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-q_su0LoSIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ef4ad8-252b-4e07-c3ef-b673d0549302"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IsXelBMp0Th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f49bbef-f1ad-4356-e4d7-b0866380aa13"
      },
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtuUnHW9NxI4"
      },
      "source": [
        "import logging\n",
        "import time\n",
        "from platform import python_version\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okG6LgqmoqO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b18feb26-f1c0-4ce7-f38a-b2183c71b54e"
      },
      "source": [
        "#load the dataset from google drive  \n",
        "df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/doc-chatbot/Emotion Phrases.csv',header=None)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joy</td>\n",
              "      <td>[ On days when I feel close to my partner and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fear</td>\n",
              "      <td>Every time I imagine that someone I love or I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anger</td>\n",
              "      <td>When I had been obviously unjustly treated and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sadness</td>\n",
              "      <td>When I think about the short time that we live...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disgust</td>\n",
              "      <td>At a gathering I found myself involuntarily si...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0                                                  1\n",
              "0      joy  [ On days when I feel close to my partner and ...\n",
              "1     fear  Every time I imagine that someone I love or I ...\n",
              "2    anger  When I had been obviously unjustly treated and...\n",
              "3  sadness  When I think about the short time that we live...\n",
              "4  disgust  At a gathering I found myself involuntarily si..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KktfXT_PoqMl"
      },
      "source": [
        "#assign the column names to dataset\n",
        "df.columns=['emotion','phrase']\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etdEGWCvoqKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2b1acf-2f1a-4d3e-aa33-0b44d189ddb9"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gensim\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop=stopwords.words('english')\n",
        "lem=WordNetLemmatizer()\n",
        "#perform preprocessing\n",
        "def clean_text(phrase):\n",
        "  tokens=gensim.utils.simple_preprocess(phrase)\n",
        "\n",
        "  clean_tokens=[token for token in tokens if token not in stop]\n",
        "  #lemmed_tokens=[lem.lemmatize(word) for word in clean_tokens]\n",
        "  sentence=' '.join(clean_tokens)\n",
        "\n",
        "  \n",
        "  return sentence"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMJkpKhYoqHO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9adf5dfd-3724-42c0-9546-6fa77d473d8a"
      },
      "source": [
        "#apply the text prerpocessing and shuffle the dataset\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df['phrase']=df['phrase'].apply(lambda x:clean_text(x))\n",
        "df = shuffle(df)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6164</th>\n",
              "      <td>anger</td>\n",
              "      <td>dancing dame social one friends interested cam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3596</th>\n",
              "      <td>guilt</td>\n",
              "      <td>thought could avoided situation one fear conce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5165</th>\n",
              "      <td>guilt</td>\n",
              "      <td>committed sin immorality mentioned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4964</th>\n",
              "      <td>joy</td>\n",
              "      <td>someone love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6685</th>\n",
              "      <td>joy</td>\n",
              "      <td>time learnt passed malawi school leaving certi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     emotion                                             phrase\n",
              "6164   anger  dancing dame social one friends interested cam...\n",
              "3596   guilt  thought could avoided situation one fear conce...\n",
              "5165   guilt                 committed sin immorality mentioned\n",
              "4964     joy                                       someone love\n",
              "6685     joy  time learnt passed malawi school leaving certi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPuJ0Q-bJps9",
        "outputId": "931684d8-121f-4428-9ed5-0b3c6e9db05d"
      },
      "source": [
        "#map the lables to numbers and store it a dictionary\r\n",
        "#possible_labels = df.sentiment.unique()\r\n",
        "possible_labels = df.emotion.unique()\r\n",
        "label_dict = {}\r\n",
        "for index, possible_label in enumerate(possible_labels):\r\n",
        "    label_dict[possible_label] = index\r\n",
        "label_dict\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anger': 0,\n",
              " 'disgust': 4,\n",
              " 'fear': 5,\n",
              " 'guilt': 1,\n",
              " 'joy': 2,\n",
              " 'sadness': 6,\n",
              " 'shame': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph7EWHgQaG2W"
      },
      "source": [
        "#labels=df.emotion.unique()\r\n",
        "labels=['fear', 'sadness', 'shame', 'anger', 'disgust', 'guilt', 'joy']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muYSxYugoqCI"
      },
      "source": [
        "#replace the categorical labels with numarical\n",
        "#df['emotion'] = df.emotion.replace(label_dict)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkH_o0TK9-4P"
      },
      "source": [
        "#check the length of the large setence in the dataframe beofre adding spl tokens\n",
        "#max_len=max([len(s.split())for s in df['phrase']])\n",
        "max_len=128\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8EmutFPlDHW"
      },
      "source": [
        "df=df.join(pd.get_dummies(df['emotion']))\n",
        "df=df.drop(['emotion'], axis = 1) "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoD0-ORbm9CJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "886e398e-2637-4b08-f4c0-aa89a0e5de88"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>anger</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>guilt</th>\n",
              "      <th>joy</th>\n",
              "      <th>sadness</th>\n",
              "      <th>shame</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6164</th>\n",
              "      <td>dancing dame social one friends interested cam...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3596</th>\n",
              "      <td>thought could avoided situation one fear conce...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5165</th>\n",
              "      <td>committed sin immorality mentioned</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4964</th>\n",
              "      <td>someone love</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6685</th>\n",
              "      <td>time learnt passed malawi school leaving certi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 phrase  anger  ...  sadness  shame\n",
              "6164  dancing dame social one friends interested cam...      1  ...        0      0\n",
              "3596  thought could avoided situation one fear conce...      0  ...        0      0\n",
              "5165                 committed sin immorality mentioned      0  ...        0      0\n",
              "4964                                       someone love      0  ...        0      0\n",
              "6685  time learnt passed malawi school leaving certi...      0  ...        0      0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7becpJfJlA0h"
      },
      "source": [
        "df_train = df.sample(frac=.30)\n",
        "df_val = df.sample(frac=.10)\n",
        "df_test = df.sample(frac=.10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHMNPM6Kop-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55daae3c-0f00-4d2e-f4c0-bbe104a26b6d"
      },
      "source": [
        "model_class = transformers.BertModel\n",
        "tokenizer_class = transformers.BertTokenizer\n",
        "pretrained_weights='bert-base-uncased'\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "bert_model = model_class.from_pretrained(pretrained_weights)\n",
        "bert_model.to(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ger5rcTuOdsG"
      },
      "source": [
        "max_seq = max_len\n",
        "def tokenize_text(df, max_seq):\n",
        "    return [\n",
        "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.phrase.values\n",
        "    ]\n",
        "def pad_text(tokenized_text, max_seq):\n",
        "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
        "def tokenize_and_pad_text(df, max_seq):\n",
        "    tokenized_text = tokenize_text(df, max_seq)\n",
        "    padded_text = pad_text(tokenized_text, max_seq)\n",
        "    return torch.tensor(padded_text)\n",
        "def targets_to_tensor(df, labels):\n",
        "    return torch.tensor(df[labels].values, dtype=torch.float32)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sriSvX-noPsm"
      },
      "source": [
        "train_indices = tokenize_and_pad_text(df_train, max_seq)\n",
        "val_indices = tokenize_and_pad_text(df_val, max_seq)\n",
        "test_indices = tokenize_and_pad_text(df_test, max_seq)\n",
        "train_indices.to(device)\n",
        "val_indices.to(device)\n",
        "test_indices.to(device)\n",
        "with torch.no_grad():\n",
        "    x_train = bert_model(train_indices.to(device))[0]  \n",
        "    x_val = bert_model(val_indices.to(device))[0]\n",
        "    x_test = bert_model(test_indices.to(device))[0]\n",
        "y_train = targets_to_tensor(df_train, labels)\n",
        "y_val = targets_to_tensor(df_val, labels)\n",
        "y_test = targets_to_tensor(df_test, labels)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irOXzsgDs5P6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab552ee-750e-4c07-9594-b3f286ae5bcd"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4321,  0.4302,  0.5643,  ..., -0.4960,  0.5820, -0.4106],\n",
              "        [ 0.0565, -0.1511,  0.5237,  ..., -0.1308, -0.0130, -0.2247],\n",
              "        [-0.5280, -0.1063,  0.5684,  ..., -0.3531, -0.1689, -0.2294],\n",
              "        ...,\n",
              "        [ 0.0857, -0.0011,  0.9181,  ..., -0.6338,  0.1725, -0.8110],\n",
              "        [ 0.0231,  0.1394,  0.8415,  ..., -0.5871,  0.0619, -0.8199],\n",
              "        [-0.0043,  0.2212,  0.8395,  ..., -0.5536,  0.0082, -0.9205]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx10VBWATRvz"
      },
      "source": [
        "class KimCNN(nn.Module):\n",
        "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
        "        super(KimCNN, self).__init__()\n",
        "        V = embed_num\n",
        "        D = embed_dim\n",
        "        C = class_num\n",
        "        Co = kernel_num\n",
        "        Ks = kernel_sizes\n",
        "        \n",
        "        self.static = static\n",
        "        self.embed = nn.Embedding(V, D)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
        "        self.Softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.static:\n",
        "            x = Variable(x)\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "        logit = self.fc1(x)  # (N, C)\n",
        "        output = self.Softmax(logit)\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYUtr6ZUv3fj"
      },
      "source": [
        "embed_num = x_train.shape[1]\n",
        "embed_dim = x_train.shape[2]\n",
        "class_num = y_train.shape[1]\n",
        "kernel_num = 3\n",
        "kernel_sizes = [2, 3, 4]\n",
        "dropout = 0.3\n",
        "static = True\n",
        "model = KimCNN(\n",
        "    embed_num=embed_num,\n",
        "    embed_dim=embed_dim,\n",
        "    class_num=class_num,\n",
        "    kernel_num=kernel_num,\n",
        "    kernel_sizes=kernel_sizes,\n",
        "    dropout=dropout,\n",
        "    static=static,\n",
        ").to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa67tDk0v3c9"
      },
      "source": [
        "n_epochs = 15\n",
        "batch_size = 64\n",
        "lr = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ODBH3pSv3Yw"
      },
      "source": [
        "def generate_batch_data(x, y, batch_size):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
        "        x_batch = x[i : i + batch_size]\n",
        "        y_batch = y[i : i + batch_size]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + batch_size < len(x):\n",
        "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEqapadFwG1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea90ee75-c015-4890-a194-719011e335fa"
      },
      "source": [
        "train_losses, val_losses = [], []\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "    model.train(True)\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        y_pred=y_pred.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= batch\n",
        "    train_losses.append(train_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "model.eval() # disable dropout for deterministic output\n",
        "# deactivate autograd engine to reduce memory usage and speed up computations\n",
        "with torch.no_grad(): \n",
        "        val_loss, batch = 0, 1\n",
        "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= batch\n",
        "        val_losses.append(val_loss)\n",
        "        print(\"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\"% (epoch + 1, train_losses[-1], val_losses[-1], elapsed))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 Train loss: 0.36. Validation loss: 0.37. Elapsed time: 15.79s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6OY34otwPgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc60340-47f9-4022-b12f-2e79f08049b5"
      },
      "source": [
        "model.eval() # disable dropout for deterministic output\n",
        "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "    y_preds = []\n",
        "    batch = 0\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
        "    y_preds_np = np.array(y_preds)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ge4ahWBIa9R"
      },
      "source": [
        "#calculate f1 score\r\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABc-9-QiA6WN",
        "outputId": "78b79dd7-fc3e-4529-b703-e72939b6d561"
      },
      "source": [
        "#enter the input\r\n",
        "input_text=input('Enter the comment:')\r\n",
        "comment=pd.Series(input_text)\r\n",
        "comment=comment.to_frame('phrase')\r\n",
        "#comment['phrase']=comment['phrase'].apply(lambda x:clean_text(x))\r\n",
        "#convert to pytorch data type\r\n",
        "comment_indices  = tokenize_and_pad_text(comment, max_seq)\r\n",
        "comment_indices.to(device)\r\n",
        "with torch.no_grad():\r\n",
        "    comment_bert = bert_model(comment_indices.to(device))[0]  \r\n",
        "#fee the data to cnn model\r\n",
        "model.eval() # disable dropout for deterministic output\r\n",
        "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\r\n",
        "    y_preds_comment = []\r\n",
        "    batch = 0\r\n",
        "    #for x_batch, batch in generate_batch_data(x_test, y_test, batch_size):\r\n",
        "    y_preds_comment = model(comment_bert)\r\n",
        "    y_preds_comment=y_preds_comment.cpu().numpy().tolist()\r\n",
        "    y_preds_comment=y_preds_comment[0]\r\n",
        "    \r\n",
        "    \r\n",
        "#sorting the list of softmax values to get max 2 probabilities\r\n",
        "sorted_integers = sorted(y_preds_comment, reverse=True)  \r\n",
        "\r\n",
        "largest_prob = sorted_integers[0] \r\n",
        "second_largest_prob = sorted_integers[1]  \r\n",
        "\r\n",
        "#Here we are extracting the max probability value index from the list and get the key(label) from label dictionary\r\n",
        "\r\n",
        "\r\n",
        "max_index1 = y_preds_comment.index(largest_prob)\r\n",
        "max_index2 = y_preds_comment.index(second_largest_prob)\r\n",
        "key_list = list(label_dict.keys()) \r\n",
        "val_list = list(label_dict.values()) \r\n",
        "  \r\n",
        "em1=(key_list[val_list.index(max_index1)]) \r\n",
        "em2=(key_list[val_list.index(max_index2)]) \r\n",
        "print('emotions :',em1, em2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the comment:my umcle is embusing me \n",
            "emotions : anger disgust\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-qNcLYpPxhR",
        "outputId": "1ea6fa51-d05c-4187-cf61-2807bd291969"
      },
      "source": [
        "#map the lables to numbers and store it a dictionary\r\n",
        "\r\n",
        "emotions=['joy', 'disgust', 'anger', 'guilt', 'sadness', 'shame','fear']\r\n",
        "\r\n",
        "em_dict = dict(zip(emotions, range(0,7)))\r\n",
        "em_dict\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anger': 2,\n",
              " 'disgust': 1,\n",
              " 'fear': 6,\n",
              " 'guilt': 3,\n",
              " 'joy': 0,\n",
              " 'sadness': 4,\n",
              " 'shame': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFuCOJysy_85"
      },
      "source": [
        "import datetime\r\n",
        "dates = [datetime.date( 2001,6,1), \r\n",
        "     datetime.date( 2001,6,2),\r\n",
        "     datetime.date( 2001,6,3),\r\n",
        "     datetime.date( 2001,6,4),\r\n",
        "     datetime.date( 2001,6,5)\r\n",
        "     ]\r\n",
        "# emotion index for each date\r\n",
        "emotion_index=[5,7,2,4,3]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P9Aj3lDTu7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "d4e7c023-0efc-4dfb-e444-d22819f9f084"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.dates\r\n",
        "%matplotlib inline\r\n",
        "fig = plt.figure()  # a new figure window\r\n",
        "ax = fig.add_subplot(1, 1, 1)  # specify (nrows, ncols, axnum)\r\n",
        "# set a title for this sub-plot\r\n",
        "ax.set_title('Time series for emotion index', fontsize=14)\r\n",
        "# set tick for x-axis\r\n",
        "ax.set_xticks(dates)\r\n",
        "# set labels for x-ticks (dates) and rotate them (45 degrees) for readability\r\n",
        "ax.set_xticklabels(dates, rotation=45, fontsize=10 )\r\n",
        "# set a title for x-axis\r\n",
        "ax.set_xlabel(\"Dates\")\r\n",
        "# set a title for y-axis\r\n",
        "ax.set_ylabel(\"Negative Levels\") \r\n",
        "ax.set_yticklabels(np.arange(10), rotation=45, fontsize=10 )               \r\n",
        "\r\n",
        "ax.xaxis.set_major_formatter(\r\n",
        "    matplotlib.dates.DateFormatter('%a %d %b %Y')\r\n",
        " )\r\n",
        "# plot nao_index as a function of dates.\r\n",
        "ax.plot(dates, emotion_index, 'r.-')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc64af0c5c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRCzz4KpU_kQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}