{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pickled bert model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWuYlp2yTNN3",
        "outputId": "5281de7e-5142-403b-8dad-053f0bb322de"
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp\r\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\r\n",
        "from pytorch_pretrained_bert import BertForSequenceClassification"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.8MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/cd/513fff674c22507caf5a983ac1aacf87fc207535ada17d720199b51b6cc3/boto3-1.16.36-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/27/f8757c8d3d11a2332677e2be978f2a524ab13d07d3766e2fff18693e6f3d/botocore-1.19.36-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 31.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.36->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.36->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.19.36 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed boto3-1.16.36 botocore-1.19.36 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABhEGOXfN0kG"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "loader = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/mindhug/pickled model/loader.pkl', 'rb'))\r\n",
        "paddding = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/mindhug/pickled model/pad_seqience.pkl', 'rb'))\r\n",
        "sampler = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/mindhug/pickled model/sampler.pkl', 'rb'))\r\n",
        "tensor_data= pickle.load(open('/content/drive/MyDrive/Colab Notebooks/mindhug/pickled model/tensor_data.pkl', 'rb'))\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc0XDEVzJGNh"
      },
      "source": [
        "label_dict={'anger': 2,\r\n",
        " 'disgust': 4,\r\n",
        " 'fear': 1,\r\n",
        " 'guilt': 6,\r\n",
        " 'happiness': 7,\r\n",
        " 'joy': 0,\r\n",
        " 'sadness': 3,\r\n",
        " 'shame': 5}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_XAbGhKRs7F",
        "outputId": "4a2d5373-f7b4-4ecf-98de-94b88a0f00ab"
      },
      "source": [
        "# load the model from disk\r\n",
        "import torch\r\n",
        "if torch.cuda.is_available():\r\n",
        "    map_location=lambda storage, loc: storage.cuda()\r\n",
        "else:\r\n",
        "    map_location='cpu'\r\n",
        "    \r\n",
        "\r\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)\r\n",
        "bert_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/mindhug/pickled model/bert_model (1).pt',map_location=map_location))\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql_SG9MqlxSH"
      },
      "source": [
        "tokenizer = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/mindhug/pickled model/bert_tokenizer.pkl', 'rb'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObI1vtA1ONL5"
      },
      "source": [
        "\r\n",
        "import pandas as pd\r\n",
        "# Load the dataset into a pandas dataframe.\r\n",
        "input_text=input('Enter the text: ')\r\n",
        "new_sentence=pd.Series(input_text)\r\n",
        "\r\n",
        "# Report the number of sentences.\r\n",
        "#print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\r\n",
        "# Create sentence and label lists\r\n",
        "sentences = new_sentence.values\r\n",
        "# tokenize test data\r\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "MAX_LEN = 128\r\n",
        "# Pad our input tokens\r\n",
        "input_ids = paddding([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\r\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "input_ids = paddding(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "# Create attention masks\r\n",
        "attention_masks = []\r\n",
        "# Create a mask of 1s for each token followed by 0s for padding\r\n",
        "for seq in input_ids:\r\n",
        "  seq_mask = [float(i>0) for i in seq]\r\n",
        "  attention_masks.append(seq_mask) \r\n",
        "\r\n",
        "# create test tensors\r\n",
        "prediction_inputs = torch.tensor(input_ids)\r\n",
        "prediction_masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "batch_size = 16\r\n",
        "prediction_data = tensor_data(prediction_inputs, prediction_masks)\r\n",
        "prediction_sampler = sampler(prediction_data)\r\n",
        "prediction_dataloader = loader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "# load the model from disk\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Put model in evaluation mode\r\n",
        "bert_model.eval()\r\n",
        "# Tracking variables \r\n",
        "predictions = []\r\n",
        "# Predict \r\n",
        "for batch in prediction_dataloader:\r\n",
        "  # Add batch to GPU\r\n",
        "  batch = tuple(t.to(device) for t in batch)\r\n",
        "  \r\n",
        "  # Unpack the inputs from our dataloader\r\n",
        "  b_input_ids, b_input_mask = batch\r\n",
        "  \r\n",
        "  # Telling the model not to compute or store gradients, saving memory and \r\n",
        "  # speeding up prediction\r\n",
        "  with torch.no_grad():\r\n",
        "      # Forward pass, calculate logit predictions\r\n",
        "      outputs = bert_model(b_input_ids, token_type_ids=None, \r\n",
        "                      attention_mask=b_input_mask)\r\n",
        "  logits = outputs[0]\r\n",
        "  # Move logits and labels to CPU\r\n",
        "  logits = logits.detach().cpu().numpy()\r\n",
        "  #label_ids = b_labels.to('cpu').numpy()\r\n",
        "  \r\n",
        "  # Store predictions and true labels\r\n",
        "  predictions.append(logits)\r\n",
        "  #true_labels.append(label_ids)\r\n",
        "print('emotions.')\r\n",
        "import torch\r\n",
        "import torch.nn.functional as F \r\n",
        "#caluclate the softmax for logits from bert model\r\n",
        "#becasue we have 7 different calsses otherwise we use sigmoid for binary classification\r\n",
        "softmax_val=F.softmax(torch.tensor(predictions[0])).tolist()\r\n",
        "#print(softmax_val)\r\n",
        "#sorting the list of softmax values to get max 2 probabilities\r\n",
        "sorted_integers = sorted(softmax_val, reverse=True)  \r\n",
        "\r\n",
        "largest_prob = sorted_integers[0]  \r\n",
        "second_largest_prob = sorted_integers[1]  \r\n",
        "\r\n",
        "#Here we are extracting the max probability value index from the list and get the key(label) from label dictionary\r\n",
        "\r\n",
        "#max_value = max((softmax_val))\r\n",
        "max_index1 = softmax_val.index(largest_prob)\r\n",
        "max_index2 = softmax_val.index(second_largest_prob)\r\n",
        "key_list = list(label_dict.keys()) \r\n",
        "val_list = list(label_dict.values()) \r\n",
        "  \r\n",
        "emotion1=(key_list[val_list.index(max_index1)]) \r\n",
        " \r\n",
        "print(emotion1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqFHLe_kaur7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}